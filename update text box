import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

# Sample DataFrame with metadata
data = {
    'Product': ['Apple iPhone 13', 'Samsung Galaxy S21', 'Google Pixel 6'],
    'Price': [999, 899, 799],
    'Release Year': [2021, 2021, 2021],
    'Description': ['Latest iPhone model', 'Flagship Samsung phone', 'Google\'s newest Pixel']
}
df = pd.DataFrame(data)

# Preprocess metadata
metadata = {
    'Product': 'product name',
    'Price': 'price',
    'Release Year': 'release year',
    'Description': 'description'
}

# Preprocess user query
def preprocess_query(query):
    query = query.lower()
    query_tokens = word_tokenize(query)
    query_tokens = [token for token in query_tokens if token not in stopwords.words('english') + list(string.punctuation)]
    return ' '.join(query_tokens)

# Function to map query to dataframe columns
def map_query_to_column(query):
    tfidf_vectorizer = TfidfVectorizer()
    corpus = list(metadata.values())
    corpus.append(query)
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)

    similarity = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
    column_index = similarity.argmax()

    return list(metadata.keys())[column_index]

# Function to get value based on user query
def get_value_based_on_query(query):
    query = preprocess_query(query)
    column = map_query_to_column(query)
    relevant_data = df[column].values.tolist()
    return relevant_data

# Example usage
user_query = "What is the price of the latest Samsung phone?"
value = get_value_based_on_query(user_query)
print("Response:", value)
