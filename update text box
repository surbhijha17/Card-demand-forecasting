import sys
from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QVBoxLayout, QTextEdit
from google.cloud import speech
import queue
import re
import time
import pyaudio

# ... (the rest of the code remains the same until the main function)

class SpeechRecognitionApp(QWidget):
    def __init__(self):
        super().__init__()

        self.init_ui()

    def init_ui(self):
        self.record_button = QPushButton('Record', self)
        self.stop_button = QPushButton('Stop', self)
        self.transcript_text = QTextEdit(self)
        self.transcript_text.setReadOnly(True)

        layout = QVBoxLayout()
        layout.addWidget(self.record_button)
        layout.addWidget(self.stop_button)
        layout.addWidget(self.transcript_text)

        self.setLayout(layout)

        self.record_button.clicked.connect(self.start_recording)
        self.stop_button.clicked.connect(self.stop_recording)

        self.setWindowTitle('Speech Recognition App')

    def start_recording(self):
        self.transcript_text.clear()
        self.thread = TranscriptionThread(self.transcript_text)
        self.thread.start()

    def stop_recording(self):
        if hasattr(self, 'thread'):
            self.thread.stop_recognition()


class TranscriptionThread(QThread):
    def __init__(self, transcript_text_widget):
        super().__init__()
        self.transcript_text_widget = transcript_text_widget
        self.stream = None
        self.client = speech.SpeechClient()

    def run(self):
        self.stream = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)
        with self.stream as audio_stream:
            self.transcript_text_widget.clear()
            while not self.stream.closed:
                audio_generator = audio_stream.generator()
                requests = (
                    speech.StreamingRecognizeRequest(audio_content=content)
                    for content in audio_generator
                )
                responses = self.client.streaming_recognize(
                    streaming_config, requests
                )
                transcript = listen_print_loop(responses, audio_stream)
                if transcript:
                    self.transcript_text_widget.append(transcript)
                time.sleep(0.1)

    def stop_recognition(self):
        if self.stream:
            self.stream.closed = True
            self.terminate()


if __name__ == '__main__':
    app = QApplication(sys.argv)
    main_win = SpeechRecognitionApp()
    main_win.show()
    sys.exit(app.exec_())
