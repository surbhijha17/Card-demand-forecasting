import tkinter as tk
import threading
from queue import Queue
from google.cloud import speech
import pyaudio
import re
import sys
import time

STREAMING_LIMIT = 240000
SAMPLE_RATE = 16000
CHUNK_SIZE = int(SAMPLE_RATE / 10)

RED = "\033[0;31m"
GREEN = "\033[0;32m"
YELLOW = "\033[0;33m"


class ResumableMicrophoneStream:
    def __init__(self, rate, chunk_size):
        self._rate = rate
        self.chunk_size = chunk_size
        self._num_channels = 1
        self._buff = Queue()
        self.closed = True
        self.start_time = self.get_current_time()
        self.restart_counter = 0
        self.audio_input = []
        self.last_audio_input = []
        self.result_end_time = 0
        self.is_final_end_time = 0
        self.final_request_end_time = 0
        self.bridging_offset = 0
        self.last_transcript_was_final = False
        self.new_stream = True
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=self._num_channels,
            rate=self._rate,
            input=True,
            frames_per_buffer=self.chunk_size,
            stream_callback=self._fill_buffer,
        )

    def __enter__(self):
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, *args, **kwargs):
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        while not self.closed:
            data = []

            if self.new_stream and self.last_audio_input:
                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)

                if chunk_time != 0:
                    if self.bridging_offset < 0:
                        self.bridging_offset = 0

                    if self.bridging_offset > self.final_request_end_time:
                        self.bridging_offset = self.final_request_end_time

                    chunks_from_ms = round(
                        (self.final_request_end_time - self.bridging_offset)
                        / chunk_time
                    )

                    self.bridging_offset = round(
                        (len(self.last_audio_input) - chunks_from_ms) * chunk_time
                    )

                    for i in range(chunks_from_ms, len(self.last_audio_input)):
                        data.append(self.last_audio_input[i])

                self.new_stream = False

            chunk = self._buff.get()
            self.audio_input.append(chunk)

            if chunk is None:
                return
            data.append(chunk)

            while True:
                try:
                    chunk = self._buff.get(block=False)

                    if chunk is None:
                        return
                    data.append(chunk)
                    self.audio_input.append(chunk)

                except queue.Empty:
                    break

            yield b"".join(data)


def get_current_time():
    return int(round(time.time() * 1000))


class SpeechRecognitionApp:
    def __init__(self, root):
        self.root = root
        self.text_widget = tk.Text(root, wrap="word", width=40, height=10)
        self.text_widget.pack(padx=10, pady=10)

        self.text_queue = Queue()
        self.recording_button = tk.Button(root, text="Start Recording", command=self.start_recording)
        self.recording_button.pack(pady=10)

        self.stream_thread = None

    def start_recording(self):
        self.recording_button.config(state=tk.DISABLED)
        self.stream_thread = threading.Thread(target=self.start_streaming)
        self.stream_thread.start()

    def start_streaming(self):
        client = speech.SpeechClient()
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=SAMPLE_RATE,
            language_code="en-US",
            max_alternatives=1,
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=config, interim_results=True
        )
        mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)

        with mic_manager as stream:
            requests = (
                speech.StreamingRecognizeRequest(audio_content=content)
                for content in stream.generator()
            )
            responses = client.streaming_recognize(streaming_config, requests)
            for transcript in self.listen_print_loop(responses, stream):
                self.text_queue.put(transcript)

        self.recording_button.config(state=tk.NORMAL)

    def listen_print_loop(self, responses, stream):
        last_transcript = ""

        for response in responses:
            if get_current_time() - stream.start_time > STREAMING_LIMIT:
                stream.start_time = get_current_time()
                break

            if not response.results:
                continue

            for result in response.results:
                if not result.alternatives:
                    continue

                transcript = result.alternatives[0].transcript

                result_seconds = 0
                result_micros = 0

                if result.result_end_time.seconds:
                    result_seconds = result.result_end_time.seconds

                if result.result_end_time.microseconds:
                    result_micros = result.result_end_time.microseconds

                stream.result_end_time = int(
                    (result_seconds * 1000) + (result_micros / 1000)
                )

                corrected_time = (
                    stream.result_end_time
                    - stream.bridging_offset
                    + (STREAMING_LIMIT * stream.restart_counter)
                )

                sys.stdout.write("\033[K")
                sys.stdout.write(str(corrected_time) + ": " + transcript + "\r")

                if result.is_final:
                    sys.stdout.write(GREEN)
                    sys.stdout.write("\033[K")
                    sys.stdout.write(str(corrected_time) + ": " + transcript + "\n")
                    last_transcript = transcript

        return last_transcript

    def update_text_widget(self):
        try:
            transcript = self.text_queue.get_nowait()
            self.text_widget.insert(tk.END, transcript + "\n")
            self.text_widget.see(tk.END)
        except queue.Empty:
            pass

        self.root.after(100, self.update_text_widget)


def main():
    root = tk.Tk()
    app = SpeechRecognitionApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
